{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "intent_df = pd.read_csv('../data/intent.csv')\n",
    "entities_df = pd.read_csv('../data/entities.csv')\n",
    "entities_df = entities_df[entities_df.word.apply(lambda x: len(x)) >= 2]\n",
    "entities_df = entities_df[entities_df.word.apply(lambda x: len(x)) <= 4]\n",
    "entities_df.to_csv('../data/entities.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_words = sorted(entities_df.word.tolist(), key=lambda x: -len(x))\n",
    "with open('../jieba_userdict/jieba_userdict.txt', 'w', encoding='utf8') as f_handle:\n",
    "    f_handle.writelines([w + '\\n' for w in new_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "entities_df['len'] = entities_df['word'].apply(lambda x: len(x))\n",
    "entities_df = entities_df.sort_values('len', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"自动更新\" #intent['questions'][125]\n",
    "intent = '测试'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_entities(question, intent, entities_df):\n",
    "    data = {}\n",
    "    find_entities = []\n",
    "    already_in = []\n",
    "    for i, e in entities_df.iterrows():\n",
    "        word = e['word']\n",
    "        s = question.find(word)\n",
    "        if s >= 0:\n",
    "            for w in already_in:\n",
    "                if w.find(word) >= 0:\n",
    "                    break\n",
    "            else:\n",
    "                already_in.append(word)\n",
    "                find_entities.append({'value': word, 'entity': e['entity'], 'start': s, 'end': s + len(word)})\n",
    "\n",
    "    data['text'] = question\n",
    "    data['intent'] = intent\n",
    "    data['entities'] = find_entities\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_data = []\n",
    "for i, row in intent_df.iterrows():\n",
    "    question = row['questions']\n",
    "    intent = row['intention']\n",
    "    common_data.append(extract_entities(question, intent, entities_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlu_data = {}\n",
    "nlu_data['rasa_nlu_data'] = {}\n",
    "nlu_data['rasa_nlu_data']['common_examples'] = common_data\n",
    "nlu_data['rasa_nlu_data']['regex_features'] = []\n",
    "nlu_data['rasa_nlu_data']['lookup_tables'] = []\n",
    "nlu_data['rasa_nlu_data']['entity_synonyms'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(nlu_data, open('../data/nlu_data.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
